# vitfly 代码框架

## 启动脚本：bash launch_evaluation.bash 1 vision

第一个参数为试验的次数，第二个参数为基于什么去执行（视觉、状态和人为手动飞）

1. 脚本先去获取传入的两个参数，并设置相应的参数。

2. 设置flightmare的环境变量和启动飞行模拟器

3. evaluation.yaml文件保存模拟的结果

4.  主循环，根据传入试验次数进行模拟，

   1. 每次迭代中如果需要重新启动模拟器，会杀死相关的所有进程并重新启动模拟器。

   2. 发布消息来重置模拟器

   3. 启动评估脚本和竞赛脚本（函数主入口）

   4. 如果当前迭代超过了300s，杀死评估脚本并设置重启模拟器的标志

   5. 将评估脚本生成内容放到evaluation.yaml文件

5. 如果ros启动了就杀死ros进程

	## 评估脚本：evaluation_node.py

定义了Evaluator类，用于评估无人机在模拟环境中的表现。

1. **_initSubscribers 设置订阅者，从无人机获取状态信息（检查是否到达终点、超时和越界）、障碍物信息和开始信息。**

2. **_initPublishers设置发布者，发布比赛结束的信号。**

3. publishFinish发布者发出信号并记录和打印总结

4. callbackState为 `QuadState` 消息的回调函数：先设置开始时间，类成员记录无人机的位置信息和时间，

   - 如果水平位置超过60m设置标志位，评估结束，调用publishFinish。
   - 如果时间超过配置的超时时间，调用abortRun
   - 如果位置超过了预设的边界框，调用abortRun

5. `callbackStart`为`Empty` 消息的回调函数，如果 is_active 为假，将其设置为真，表示评估开始。

6. `callbackObstacles`回调函数，如果与障碍物的距离小于障碍物的尺度（即发生了碰撞），增加碰撞计数 (`self.crash`)，并打印碰撞信息，设置 `hit_obstacle` 为真。否则，置 `hit_obstacle` 为假。

7. abortRun在未能到达目标或超出时间限制时被调用，记录失败的尝试，并将总结信息写入 `summary.yaml` 文件，并关闭ros节点

8. writeSummary用于将评估过程中的数据集写入文件，并生成图表。（目前未使用）

   - 在 `labutils/stored_metrics` 路径下将无人机的路径数据保存为 CSV 文件（path.csv），并生成 XYZ 路径图（XYZ Plots.png）

   - 将无人机与最近障碍物的距离数据保存为 CSV 文件（dist.csv），并生成距离图表（nearestDist.png）。

   - 获取训练集目录的最新名称，以便后续提取更多统计信息

   - 评估过程中的时间和其他指标（如碰撞次数）保存到 `scalarMetrics.dat` 文件。

9. printSummary方法用于在评估结束后打印和记录总结信息。
   - 设置字典 summary的 "Success" 键的值为 True（如果未发生碰撞）或 False（如果发生碰撞）。
   - 打印到达目标的总时间、中间时间点和碰撞次数
   - 将总结信息写入 summary.yaml 文件
   - 生成路径图、速度图和障碍物距离图，输出到终端
   - 关闭ros节点

**主程序：** 从 evaluation_config.yaml 文件中读取配置信息，并根据命令行参数或当前日期时间创建实验名称，然后创建 Evaluator 实例并进入ROS循环

## 	竞赛脚本 run_competition.py

1. 定义AgilePilotNode类，接受参数

   vision_based：是否基于视觉进行飞行。
   model_type 和 model_path：用于加载训练好的深度学习模型。
   desVel：期望的无人机速度。
   keyboard：是否使用键盘输入来控制无人机

2. ROS订阅者：订阅开始导航信号、无人机状态、深度图像、障碍物信息、无人机控制推力角速度信息、键盘输入、rgb图像信息

3. ROS发布者：发布控制命令和调试图像信息。

4. 回调函数：

   - rgb_callback：响应收到的RGB图像，并将图像消息转换为Opencv的图像
   - cmd_callback:收到控制指令，并赋值给成员变量
   - keyboard_callback：记录受到按键输入消息的时间并赋值给对应变量
   -  ***img_callback*** :响应收到的深度图像数据:
     - 深拷贝上一次获取的深度图像
     - 如果不是基于视觉计算或是没有获取到状态就返回
     - 进入根据深度图像计算控制指令的主函数
     - 发布调试图像、发布控制命令
     - 记录飞行器特定时间间隔的状态信息，定期保存数据到指定文件夹下面的data.csv文件
   - state_callback:响应收到的无人机状态，并赋值给对应成员变量（信息包括位置、速度、加速度、角速度）
   - obstacle_callback：
     - 如果是基于视觉计算、未获取到状态、没获取rgb图像就返回
     - 进入根据状态计算控制指令的主函数并发布控制指令
     - 记录飞行器特定时间间隔的状态信息，保存到data.csv文件
   - start_callback，打印开始信号并赋值标志位
   
   ## 核心函数 user_code.py

### compute_command_state_based：

它用于计算基于无人机当前状态和障碍物信息的控制命令。这个函数可以根据不同的情况和输入参数采取不同的策略来生成控制命令。

1. method = 0:  先生成一个二维网格，在该网格中寻找到一个有效的路径点。列表按照螺旋从中心向外遍历航点，再去检测每个航点是否避开了障碍物，没有找到有效航点打印消息并使用更小的障碍物膨胀因子来检查。最后去计算线性速度命令
2. method = 1： 这段代码的目的是遍历航点网格，并根据找到的路径点计算出期望的速度向量。

### 深度学习模型输入输出：

**数据输入**：

x[0]: 图像（1,1, h=60, w= 90）

x[1] :期望速度（1，1）（默认方向为向前）

x[2]: 四元数（1，4）

**数据输出**：

(3, ) :三个方向的速度

隐藏层

### ***训练时输入输出***：

数据输入：轨迹长度为T

x[0]: 图像（T,1, h=60, w= 90）

x[1] :期望速度（T，1）（默认方向为向前）

x[2]: 四元数（T，4）

数据输出：

三个方向速度 （T，3）

隐藏层

